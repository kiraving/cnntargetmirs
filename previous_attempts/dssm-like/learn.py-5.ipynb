{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import permutation\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, Sequential \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape, Merge\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras import backend\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.core import Dense, Lambda, Reshape\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_epoch = 200\n",
    "J = 0\n",
    "#J = 4 #nb of negative targets\n",
    "L = 32 #for last Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For training\n",
    "genes_1 = np.load('input10k-7gram_gene_seed8.npy') # 100 000 pairs from the head of \"input_for_neuronet\n",
    "mirs_1 = np.load('input10k-7gram_mir_seed8.npy')\n",
    "genes_0 = np.load('control10k-7gram_gene_seed8.npy') # 100 000 pairs from the head of \"input_for_neuronet\n",
    "mirs_0 = np.load('control10k-7gram_mir_seed8.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(16.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Generation of 4 'negative' genes by simply shuffling the original genes' set\n",
    "perm = permutation(len(genes_1))\n",
    "genes_01 = genes_1[perm]\n",
    "print perm, genes_01\n",
    "perm = permutation(len(genes_1))\n",
    "genes_02 = genes_1[perm]\n",
    "perm = permutation(len(genes_1))\n",
    "genes_03 = genes_1[perm]\n",
    "perm = permutation(len(genes_1))\n",
    "genes_04 = genes_1[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genes = np.concatenate((genes_1, genes_0))\n",
    "                        #, genes_02, genes_03\n",
    "                        #, genes_04))\n",
    "targets_1 = np.empty(genes_1.shape[0])\n",
    "targets_1.fill(1) \n",
    "targets_0 = np.zeros(genes_1.shape[0])\n",
    "targets = np.concatenate((targets_1, targets_0))\n",
    "mirs = np.concatenate((mirs_1, mirs_0))\n",
    "                       #, mirs_1, mirs_1\n",
    "                       #, mirs_1))\n",
    "\n",
    "perm = permutation(len(genes))\n",
    "genes = genes[perm]\n",
    "mirs = mirs[perm]\n",
    "targets = targets[perm]\n",
    "# For test\n",
    "genes_t = genes[9000:-1]\n",
    "mirs_t = mirs[9000:-1]\n",
    "targets_t = targets[9000:-1]\n",
    "\n",
    "genes = genes[0:9000]\n",
    "mirs = mirs[0:9000]\n",
    "targets = targets[0:9000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test\n",
    "genes_t = np.load('input10ktail-7gram_mir_seed8.npy') # 10 000 pairs from the tail\n",
    "mirs_t = np.load('input10ktail-7gram_gene_seed8.npy')\n",
    "perm = permutation(len(genes_1t))\n",
    "genes_01t = genes_1[perm]\n",
    "perm = permutation(len(genes_1t))\n",
    "genes_02t = genes_1[perm]\n",
    "perm = permutation(len(genes_1t))\n",
    "genes_03t = genes_1[perm]\n",
    "#perm = permutation(len(genes_1t))\n",
    "#genes_04t = genes_1[perm]\n",
    "\n",
    "#genes_t = np.concatenate((genes_1t))\n",
    "                          #, genes_01t, genes_02t, genes_03t))\n",
    "                          #, genes_04t))\n",
    "targets_t = np.empty(genes_1t.shape[0])\n",
    "targets_t.fill(1) \n",
    "targets_0t = np.zeros(genes_1t.shape[0])\n",
    "#targets_t = np.concatenate((targets_1t))\n",
    "                            #, targets_0t))\n",
    "#mirs_t = np.concatenate((mirs_1t))\n",
    "                         #, mirs_1t, mirs_1t, mirs_1t))\n",
    "                         #, mirs_1t))\n",
    "\n",
    "perm_t = permutation(len(genes_t))\n",
    "genes_t = genes_t[perm_t]\n",
    "mirs_t = mirs_t[perm_t]\n",
    "targets_t = targets_t[perm_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = 64\n",
    "dense2 = 32\n",
    "dense3 = 1\n",
    "\n",
    "# targets \n",
    "genes_branch = Sequential()\n",
    "genes_branch.add(Dense(dense1, input_dim=genes_1.shape[1]))\n",
    "genes_branch.add(Activation('relu'))\n",
    "genes_branch.add(Dropout(0.5))\n",
    "genes_branch.add(Dense(dense2))\n",
    "genes_branch.add(Activation('relu'))\n",
    "genes_branch.add(Dropout(0.5))\n",
    "#genes_branch.add(Dense(dense3))\n",
    "#genes_branch.add(Activation('sigmoid'))\n",
    "\n",
    "# microRNAs\n",
    "mirs_branch = Sequential()\n",
    "mirs_branch.add(Dense(dense1, input_dim=genes_1.shape[1]))\n",
    "mirs_branch.add(Activation('relu'))\n",
    "mirs_branch.add(Dropout(0.5))\n",
    "mirs_branch.add(Dense(dense2))\n",
    "mirs_branch.add(Activation('relu'))\n",
    "mirs_branch.add(Dropout(0.5))\n",
    "#mirs_branch.add(Dense(dense3))\n",
    "#mirs_branch.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1)\n",
      "(None, 1)\n"
     ]
    }
   ],
   "source": [
    "# R_Q_D= the cosine similarity between microRNAs and genes\n",
    "R_Q_D = Merge([mirs_branch, genes_branch], mode = 'concat') # See equation (4).\n",
    "model_Rs = Sequential()\n",
    "#model_Rs.add(concat_Rs)\n",
    "model_Rs.add(R_Q_D)\n",
    "model_Rs.add(Dense(1))\n",
    "model_Rs.add(Activation('sigmoid'))\n",
    "print model_Rs.output_shape\n",
    "#model_Rs.add(Reshape((J + 1, 1)))\n",
    "print model_Rs.output_shape\n",
    "#weight = np.array([1]).reshape(1, 1, 1,1)\n",
    "#model_Rs.add(Conv1D(1, 1, border_mode = \"same\", \n",
    " #                    input_shape = (J + 1, 1), \n",
    "#                  activation = \"linear\", bias = False,\n",
    "#                       weights = [weight]))\n",
    "#model_Rs.add(Reshape((J + 1, )))\n",
    "#print model_Rs.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.00015, decay=1e-6, momentum=0.7, nesterov=True)\n",
    "#model_Rs.add(Lambda(lambda x: backend.softmax(x), output_shape = (J + 1, )))\n",
    "model_Rs.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics=['accuracy','recall','precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.6327 - acc: 0.6474 - recall: 0.7389 - precision: 0.6294 - val_loss: 0.5733 - val_acc: 0.7833 - val_recall: 0.8257 - val_precision: 0.7458\n",
      "Epoch 2/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.5700 - acc: 0.7286 - recall: 0.6818 - precision: 0.7525 - val_loss: 0.5242 - val_acc: 0.7944 - val_recall: 0.7378 - val_precision: 0.8131\n",
      "Epoch 3/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.5234 - acc: 0.7590 - recall: 0.6908 - precision: 0.7991 - val_loss: 0.4958 - val_acc: 0.8044 - val_recall: 0.7582 - val_precision: 0.8171\n",
      "Epoch 4/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.5010 - acc: 0.7760 - recall: 0.7072 - precision: 0.8198 - val_loss: 0.4767 - val_acc: 0.8133 - val_recall: 0.7841 - val_precision: 0.8155\n",
      "Epoch 5/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.4789 - acc: 0.7889 - recall: 0.7261 - precision: 0.8297 - val_loss: 0.4509 - val_acc: 0.8144 - val_recall: 0.7725 - val_precision: 0.8256\n",
      "Epoch 6/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.4435 - acc: 0.8032 - recall: 0.7520 - precision: 0.8380 - val_loss: 0.4351 - val_acc: 0.8278 - val_recall: 0.7866 - val_precision: 0.8406\n",
      "Epoch 7/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.4298 - acc: 0.8100 - recall: 0.7606 - precision: 0.8423 - val_loss: 0.4257 - val_acc: 0.8333 - val_recall: 0.8053 - val_precision: 0.8376\n",
      "Epoch 8/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.4087 - acc: 0.8195 - recall: 0.7767 - precision: 0.8492 - val_loss: 0.4255 - val_acc: 0.8244 - val_recall: 0.8266 - val_precision: 0.8084\n",
      "Epoch 9/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.3956 - acc: 0.8320 - recall: 0.7983 - precision: 0.8555 - val_loss: 0.4222 - val_acc: 0.8289 - val_recall: 0.8406 - val_precision: 0.8072\n",
      "Epoch 10/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.3811 - acc: 0.8396 - recall: 0.8115 - precision: 0.8589 - val_loss: 0.4162 - val_acc: 0.8289 - val_recall: 0.8523 - val_precision: 0.8006\n",
      "Epoch 11/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.3570 - acc: 0.8485 - recall: 0.8262 - precision: 0.8645 - val_loss: 0.4087 - val_acc: 0.8300 - val_recall: 0.8290 - val_precision: 0.8159\n",
      "Epoch 12/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.3460 - acc: 0.8537 - recall: 0.8392 - precision: 0.8642 - val_loss: 0.3982 - val_acc: 0.8322 - val_recall: 0.8263 - val_precision: 0.8208\n",
      "Epoch 13/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.3320 - acc: 0.8617 - recall: 0.8440 - precision: 0.8747 - val_loss: 0.3999 - val_acc: 0.8400 - val_recall: 0.8425 - val_precision: 0.8236\n",
      "Epoch 14/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.3192 - acc: 0.8695 - recall: 0.8562 - precision: 0.8787 - val_loss: 0.3970 - val_acc: 0.8378 - val_recall: 0.8380 - val_precision: 0.8228\n",
      "Epoch 15/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.3118 - acc: 0.8727 - recall: 0.8625 - precision: 0.8802 - val_loss: 0.3983 - val_acc: 0.8378 - val_recall: 0.8333 - val_precision: 0.8258\n",
      "Epoch 16/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.3002 - acc: 0.8759 - recall: 0.8626 - precision: 0.8860 - val_loss: 0.4028 - val_acc: 0.8400 - val_recall: 0.8450 - val_precision: 0.8220\n",
      "Epoch 17/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.2966 - acc: 0.8775 - recall: 0.8708 - precision: 0.8821 - val_loss: 0.4007 - val_acc: 0.8411 - val_recall: 0.8474 - val_precision: 0.8224\n",
      "Epoch 18/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.2755 - acc: 0.8912 - recall: 0.8873 - precision: 0.8936 - val_loss: 0.4079 - val_acc: 0.8389 - val_recall: 0.8570 - val_precision: 0.8132\n",
      "Epoch 19/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.2702 - acc: 0.8894 - recall: 0.8876 - precision: 0.8911 - val_loss: 0.4019 - val_acc: 0.8433 - val_recall: 0.8430 - val_precision: 0.8292\n",
      "Epoch 20/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.2653 - acc: 0.8960 - recall: 0.8895 - precision: 0.9017 - val_loss: 0.3945 - val_acc: 0.8433 - val_recall: 0.8452 - val_precision: 0.8278\n",
      "Epoch 21/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.2487 - acc: 0.9017 - recall: 0.8983 - precision: 0.9043 - val_loss: 0.4059 - val_acc: 0.8400 - val_recall: 0.8523 - val_precision: 0.8177\n",
      "Epoch 22/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.2396 - acc: 0.9105 - recall: 0.9100 - precision: 0.9104 - val_loss: 0.3936 - val_acc: 0.8478 - val_recall: 0.8360 - val_precision: 0.8421\n",
      "Epoch 23/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.2330 - acc: 0.9105 - recall: 0.9084 - precision: 0.9114 - val_loss: 0.4020 - val_acc: 0.8433 - val_recall: 0.8454 - val_precision: 0.8278\n",
      "Epoch 24/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.2176 - acc: 0.9193 - recall: 0.9186 - precision: 0.9194 - val_loss: 0.3927 - val_acc: 0.8478 - val_recall: 0.8337 - val_precision: 0.8435\n",
      "Epoch 25/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.2107 - acc: 0.9216 - recall: 0.9189 - precision: 0.9238 - val_loss: 0.4275 - val_acc: 0.8411 - val_recall: 0.8569 - val_precision: 0.8168\n",
      "Epoch 26/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.2130 - acc: 0.9209 - recall: 0.9217 - precision: 0.9204 - val_loss: 0.4119 - val_acc: 0.8444 - val_recall: 0.8476 - val_precision: 0.8280\n",
      "Epoch 27/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1994 - acc: 0.9272 - recall: 0.9285 - precision: 0.9255 - val_loss: 0.4013 - val_acc: 0.8467 - val_recall: 0.8337 - val_precision: 0.8415\n",
      "Epoch 28/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1949 - acc: 0.9314 - recall: 0.9286 - precision: 0.9332 - val_loss: 0.4264 - val_acc: 0.8411 - val_recall: 0.8524 - val_precision: 0.8196\n",
      "Epoch 29/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1857 - acc: 0.9317 - recall: 0.9286 - precision: 0.9338 - val_loss: 0.4012 - val_acc: 0.8533 - val_recall: 0.8313 - val_precision: 0.8552\n",
      "Epoch 30/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1749 - acc: 0.9351 - recall: 0.9326 - precision: 0.9373 - val_loss: 0.4198 - val_acc: 0.8456 - val_recall: 0.8454 - val_precision: 0.8315\n",
      "Epoch 31/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1703 - acc: 0.9380 - recall: 0.9398 - precision: 0.9367 - val_loss: 0.4199 - val_acc: 0.8489 - val_recall: 0.8482 - val_precision: 0.8358\n",
      "Epoch 32/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1628 - acc: 0.9379 - recall: 0.9402 - precision: 0.9354 - val_loss: 0.4174 - val_acc: 0.8533 - val_recall: 0.8434 - val_precision: 0.8470\n",
      "Epoch 33/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1647 - acc: 0.9425 - recall: 0.9423 - precision: 0.9423 - val_loss: 0.4203 - val_acc: 0.8589 - val_recall: 0.8386 - val_precision: 0.8607\n",
      "Epoch 34/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1515 - acc: 0.9463 - recall: 0.9490 - precision: 0.9437 - val_loss: 0.4397 - val_acc: 0.8533 - val_recall: 0.8528 - val_precision: 0.8407\n",
      "Epoch 35/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1509 - acc: 0.9470 - recall: 0.9460 - precision: 0.9480 - val_loss: 0.4343 - val_acc: 0.8533 - val_recall: 0.8528 - val_precision: 0.8405\n",
      "Epoch 36/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1431 - acc: 0.9464 - recall: 0.9481 - precision: 0.9445 - val_loss: 0.4438 - val_acc: 0.8611 - val_recall: 0.8481 - val_precision: 0.8576\n",
      "Epoch 37/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1479 - acc: 0.9481 - recall: 0.9468 - precision: 0.9489 - val_loss: 0.4305 - val_acc: 0.8633 - val_recall: 0.8504 - val_precision: 0.8601\n",
      "Epoch 38/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1338 - acc: 0.9536 - recall: 0.9520 - precision: 0.9544 - val_loss: 0.4450 - val_acc: 0.8622 - val_recall: 0.8526 - val_precision: 0.8566\n",
      "Epoch 39/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1282 - acc: 0.9556 - recall: 0.9525 - precision: 0.9583 - val_loss: 0.4661 - val_acc: 0.8589 - val_recall: 0.8526 - val_precision: 0.8506\n",
      "Epoch 40/40\n",
      "8100/8100 [==============================] - 0s - loss: 0.1299 - acc: 0.9551 - recall: 0.9566 - precision: 0.9538 - val_loss: 0.4627 - val_acc: 0.8689 - val_recall: 0.8554 - val_precision: 0.8676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f44557e6dd0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Rs.fit([mirs, genes], targets,\n",
    "             batch_size=batch_size,\n",
    "              nb_epoch=40,\n",
    "              validation_split=0.1)\n",
    "            #shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10999 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43617190858084176,\n",
       " 0.86435130467489851,\n",
       " 0.84643279279792449,\n",
       " 0.87918453712833611]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "model_Rs.evaluate([mirs_t, genes_t], targets_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For training\n",
    "genes_1 = np.load('input100k-7gram_gene_seed8.npy') # 100 000 pairs from the head of \"input_for_neuronet\n",
    "mirs_1 = np.load('input100k-7gram_mir_seed8.npy')\n",
    "genes_0 = np.load('control100k-7gram_gene_seed8.npy') # 100 000 pairs from the head of \"input_for_neuronet\n",
    "mirs_0 = np.load('control100k-7gram_mir_seed8.npy')\n",
    "\n",
    "genes = np.concatenate((genes_1, genes_0))\n",
    "                        #, genes_02, genes_03\n",
    "                        #, genes_04))\n",
    "targets_1 = np.empty(genes_1.shape[0])\n",
    "targets_1.fill(1) \n",
    "targets_0 = np.zeros(genes_1.shape[0])\n",
    "targets = np.concatenate((targets_1, targets_0))\n",
    "mirs = np.concatenate((mirs_1, mirs_0))\n",
    "                       #, mirs_1, mirs_1\n",
    "                       #, mirs_1))\n",
    "\n",
    "perm = permutation(len(genes))\n",
    "genes = genes[perm]\n",
    "mirs = mirs[perm]\n",
    "targets = targets[perm]\n",
    "# For test\n",
    "genes_t = genes[90000:-1]\n",
    "mirs_t = mirs[90000:-1]\n",
    "targets_t = targets[90000:-1]\n",
    "\n",
    "genes = genes[0:90000]\n",
    "mirs = mirs[0:90000]\n",
    "targets = targets[0:90000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = 64\n",
    "dense2 = 32\n",
    "dense3 = 1\n",
    "\n",
    "# targets \n",
    "genes_branch = Sequential()\n",
    "genes_branch.add(Dense(dense1, input_dim=genes_1.shape[1]))\n",
    "genes_branch.add(Activation('relu'))\n",
    "genes_branch.add(Dropout(0.5))\n",
    "genes_branch.add(Dense(dense2))\n",
    "genes_branch.add(Activation('relu'))\n",
    "genes_branch.add(Dropout(0.5))\n",
    "#genes_branch.add(Dense(dense3))\n",
    "#genes_branch.add(Activation('sigmoid'))\n",
    "\n",
    "# microRNAs\n",
    "mirs_branch = Sequential()\n",
    "mirs_branch.add(Dense(dense1, input_dim=genes_1.shape[1]))\n",
    "mirs_branch.add(Activation('relu'))\n",
    "mirs_branch.add(Dropout(0.5))\n",
    "mirs_branch.add(Dense(dense2))\n",
    "mirs_branch.add(Activation('relu'))\n",
    "mirs_branch.add(Dropout(0.5))\n",
    "#mirs_branch.add(Dense(dense3))\n",
    "#mirs_branch.add(Activation('sigmoid'))\n",
    "R_Q_D = Merge([mirs_branch, genes_branch], mode = 'concat') # See equation (4).\n",
    "model_Rs = Sequential()\n",
    "#model_Rs.add(concat_Rs)\n",
    "model_Rs.add(R_Q_D)\n",
    "model_Rs.add(Dense(1))\n",
    "model_Rs.add(Activation('sigmoid'))\n",
    "sgd = SGD(lr=0.00015, decay=1e-6, momentum=0.7, nesterov=True)\n",
    "#model_Rs.add(Lambda(lambda x: backend.softmax(x), output_shape = (J + 1, )))\n",
    "model_Rs.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics=['accuracy','recall','precision'])\n",
    "model_Rs.fit([mirs, genes], targets,\n",
    "             batch_size=batch_size,\n",
    "              nb_epoch=20,\n",
    "              validation_split=0.1)\n",
    "            #shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "model_Rs.evaluate([mirs_t, genes_t], targets_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training\n",
    "genes_1 = np.load('input100k-7gram_gene_seed16.npy') # 10 000 pairs from the head of \"input_for_neuronet\n",
    "mirs_1 = np.load('input100k-7gram_mir_seed16.npy')\n",
    "genes_0 = np.load('control100k-7gram_gene_seed16.npy') # 10 000 pairs from the head of \"input_for_neuronet\n",
    "mirs_0 = np.load('control100k-7gram_mir_seed16.npy')\n",
    "\n",
    "genes = np.concatenate((genes_1, genes_0, genes_0, genes_0))\n",
    "                        #, genes_02, genes_03\n",
    "                        #, genes_04))\n",
    "targets_1 = np.empty(genes_1.shape[0])\n",
    "targets_1.fill(1) \n",
    "targets_0 = np.zeros(3*genes_1.shape[0])\n",
    "targets = np.concatenate((targets_1, targets_0))\n",
    "mirs = np.concatenate((mirs_1, mirs_0, mirs_0, mirs_0))\n",
    "                       #, mirs_1, mirs_1\n",
    "                       #, mirs_1))\n",
    "\n",
    "perm = permutation(len(genes))\n",
    "genes = genes[perm]\n",
    "mirs = mirs[perm]\n",
    "targets = targets[perm]\n",
    "# For test\n",
    "train_size = 0.8*len(genes)\n",
    "genes_t = genes[train_size:-1]\n",
    "mirs_t = mirs[train_size:-1]\n",
    "targets_t = targets[train_size:-1]\n",
    "\n",
    "genes = genes[0:train_size]\n",
    "mirs = mirs[0:train_size]\n",
    "targets = targets[0:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28800 samples, validate on 3200 samples\n",
      "Epoch 1/20\n",
      "28800/28800 [==============================] - 2s - loss: 0.3495 - acc: 0.8599 - recall: 0.5477 - precision: 0.8145 - val_loss: 0.1533 - val_acc: 0.9509 - val_recall: 0.8318 - val_precision: 0.9679\n",
      "Epoch 2/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.1623 - acc: 0.9440 - recall: 0.8391 - precision: 0.9285 - val_loss: 0.1025 - val_acc: 0.9697 - val_recall: 0.8949 - val_precision: 0.9854\n",
      "Epoch 3/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.1073 - acc: 0.9660 - recall: 0.9079 - precision: 0.9536 - val_loss: 0.1188 - val_acc: 0.9694 - val_recall: 0.8848 - val_precision: 0.9943\n",
      "Epoch 4/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0803 - acc: 0.9767 - recall: 0.9387 - precision: 0.9683 - val_loss: 0.0831 - val_acc: 0.9800 - val_recall: 0.9306 - val_precision: 0.9886\n",
      "Epoch 5/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0633 - acc: 0.9839 - recall: 0.9577 - precision: 0.9768 - val_loss: 0.1070 - val_acc: 0.9784 - val_recall: 0.9197 - val_precision: 0.9944\n",
      "Epoch 6/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0524 - acc: 0.9860 - recall: 0.9622 - precision: 0.9814 - val_loss: 0.0739 - val_acc: 0.9850 - val_recall: 0.9523 - val_precision: 0.9865\n",
      "Epoch 7/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0449 - acc: 0.9887 - recall: 0.9712 - precision: 0.9836 - val_loss: 0.1043 - val_acc: 0.9816 - val_recall: 0.9305 - val_precision: 0.9963\n",
      "Epoch 8/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0375 - acc: 0.9901 - recall: 0.9759 - precision: 0.9844 - val_loss: 0.1263 - val_acc: 0.9791 - val_recall: 0.9206 - val_precision: 0.9962\n",
      "Epoch 9/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0337 - acc: 0.9918 - recall: 0.9785 - precision: 0.9874 - val_loss: 0.1323 - val_acc: 0.9775 - val_recall: 0.9143 - val_precision: 0.9962\n",
      "Epoch 10/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0301 - acc: 0.9927 - recall: 0.9807 - precision: 0.9900 - val_loss: 0.1207 - val_acc: 0.9831 - val_recall: 0.9360 - val_precision: 0.9962\n",
      "Epoch 11/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0262 - acc: 0.9937 - recall: 0.9841 - precision: 0.9901 - val_loss: 0.1393 - val_acc: 0.9816 - val_recall: 0.9304 - val_precision: 0.9963\n",
      "Epoch 12/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0232 - acc: 0.9947 - recall: 0.9890 - precision: 0.9898 - val_loss: 0.1503 - val_acc: 0.9775 - val_recall: 0.9151 - val_precision: 0.9962\n",
      "Epoch 13/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0243 - acc: 0.9949 - recall: 0.9878 - precision: 0.9919 - val_loss: 0.1592 - val_acc: 0.9781 - val_recall: 0.9167 - val_precision: 0.9962\n",
      "Epoch 14/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0202 - acc: 0.9953 - recall: 0.9885 - precision: 0.9925 - val_loss: 0.1499 - val_acc: 0.9800 - val_recall: 0.9239 - val_precision: 0.9962\n",
      "Epoch 15/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0194 - acc: 0.9955 - recall: 0.9905 - precision: 0.9916 - val_loss: 0.1701 - val_acc: 0.9772 - val_recall: 0.9135 - val_precision: 0.9962\n",
      "Epoch 16/20\n",
      "28800/28800 [==============================] - 2s - loss: 0.0202 - acc: 0.9962 - recall: 0.9908 - precision: 0.9941 - val_loss: 0.1677 - val_acc: 0.9800 - val_recall: 0.9242 - val_precision: 0.9962\n",
      "Epoch 17/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0159 - acc: 0.9968 - recall: 0.9924 - precision: 0.9949 - val_loss: 0.1683 - val_acc: 0.9806 - val_recall: 0.9264 - val_precision: 0.9962\n",
      "Epoch 18/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0160 - acc: 0.9966 - recall: 0.9922 - precision: 0.9942 - val_loss: 0.2136 - val_acc: 0.9756 - val_recall: 0.9062 - val_precision: 0.9962\n",
      "Epoch 19/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0160 - acc: 0.9965 - recall: 0.9919 - precision: 0.9939 - val_loss: 0.1738 - val_acc: 0.9806 - val_recall: 0.9265 - val_precision: 0.9962\n",
      "Epoch 20/20\n",
      "28800/28800 [==============================] - 1s - loss: 0.0155 - acc: 0.9968 - recall: 0.9933 - precision: 0.9940 - val_loss: 0.1859 - val_acc: 0.9797 - val_recall: 0.9224 - val_precision: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6cf840fa90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense1 = 64\n",
    "dense2 = 32\n",
    "dense3 = 1\n",
    "\n",
    "# targets \n",
    "genes_branch = Sequential()\n",
    "genes_branch.add(Dense(dense1, input_dim=genes_1.shape[1]))\n",
    "genes_branch.add(Activation('relu'))\n",
    "genes_branch.add(Dropout(0.5))\n",
    "genes_branch.add(Dense(dense2))\n",
    "genes_branch.add(Activation('relu'))\n",
    "genes_branch.add(Dropout(0.5))\n",
    "#genes_branch.add(Dense(dense3))\n",
    "#genes_branch.add(Activation('sigmoid'))\n",
    "\n",
    "# microRNAs\n",
    "mirs_branch = Sequential()\n",
    "mirs_branch.add(Dense(dense1, input_dim=genes_1.shape[1]))\n",
    "mirs_branch.add(Activation('relu'))\n",
    "mirs_branch.add(Dropout(0.5))\n",
    "mirs_branch.add(Dense(dense2))\n",
    "mirs_branch.add(Activation('relu'))\n",
    "mirs_branch.add(Dropout(0.5))\n",
    "#mirs_branch.add(Dense(dense3))\n",
    "#mirs_branch.add(Activation('sigmoid'))\n",
    "R_Q_D = Merge([mirs_branch, genes_branch], mode = 'concat') # See equation (4).\n",
    "model_Rs = Sequential()\n",
    "#model_Rs.add(concat_Rs)\n",
    "model_Rs.add(R_Q_D)\n",
    "model_Rs.add(Dense(1))\n",
    "model_Rs.add(Activation('sigmoid'))\n",
    "sgd = SGD(lr=0.00015, decay=1e-6, momentum=0.7, nesterov=True)\n",
    "#model_Rs.add(Lambda(lambda x: backend.softmax(x), output_shape = (J + 1, )))\n",
    "model_Rs.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics=['accuracy','recall','precision'])\n",
    "model_Rs.fit([mirs, genes], targets,\n",
    "             batch_size=batch_size,\n",
    "              nb_epoch=20,\n",
    "              validation_split=0.1)\n",
    "            #shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7999/7999 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16960426814961727,\n",
       " 0.97849731217147207,\n",
       " 0.91971187983353242,\n",
       " 0.99563052490631154]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Rs.evaluate([mirs_t, genes_t], targets_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8100 samples, validate on 900 samples\n",
      "Epoch 1/400\n",
      "8100/8100 [==============================] - 1s - loss: 0.8470 - acc: 0.4968 - val_loss: 0.7223 - val_acc: 0.5122\n",
      "Epoch 2/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.7959 - acc: 0.5062 - val_loss: 0.6917 - val_acc: 0.5422\n",
      "Epoch 3/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.7738 - acc: 0.5165 - val_loss: 0.6745 - val_acc: 0.5556\n",
      "Epoch 4/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.7369 - acc: 0.5407 - val_loss: 0.6645 - val_acc: 0.5622\n",
      "Epoch 5/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.7232 - acc: 0.5330 - val_loss: 0.6588 - val_acc: 0.5622\n",
      "Epoch 6/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.7166 - acc: 0.5358 - val_loss: 0.6549 - val_acc: 0.5622\n",
      "Epoch 7/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.7173 - acc: 0.5388 - val_loss: 0.6521 - val_acc: 0.5567\n",
      "Epoch 8/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6981 - acc: 0.5544 - val_loss: 0.6500 - val_acc: 0.5544\n",
      "Epoch 9/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6944 - acc: 0.5611 - val_loss: 0.6481 - val_acc: 0.5578\n",
      "Epoch 10/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6902 - acc: 0.5627 - val_loss: 0.6463 - val_acc: 0.5644\n",
      "Epoch 11/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6858 - acc: 0.5705 - val_loss: 0.6448 - val_acc: 0.5678\n",
      "Epoch 12/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6820 - acc: 0.5777 - val_loss: 0.6432 - val_acc: 0.5744\n",
      "Epoch 13/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6744 - acc: 0.5932 - val_loss: 0.6417 - val_acc: 0.5767\n",
      "Epoch 14/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6813 - acc: 0.5858 - val_loss: 0.6401 - val_acc: 0.5833\n",
      "Epoch 15/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6761 - acc: 0.5965 - val_loss: 0.6384 - val_acc: 0.5867\n",
      "Epoch 16/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6668 - acc: 0.5962 - val_loss: 0.6369 - val_acc: 0.5878\n",
      "Epoch 17/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6648 - acc: 0.5995 - val_loss: 0.6352 - val_acc: 0.5956\n",
      "Epoch 18/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6690 - acc: 0.5942 - val_loss: 0.6335 - val_acc: 0.5978\n",
      "Epoch 19/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6613 - acc: 0.6002 - val_loss: 0.6319 - val_acc: 0.6044\n",
      "Epoch 20/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6607 - acc: 0.6022 - val_loss: 0.6301 - val_acc: 0.6089\n",
      "Epoch 21/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6525 - acc: 0.6158 - val_loss: 0.6283 - val_acc: 0.6156\n",
      "Epoch 22/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6607 - acc: 0.6091 - val_loss: 0.6267 - val_acc: 0.6278\n",
      "Epoch 23/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6524 - acc: 0.6157 - val_loss: 0.6250 - val_acc: 0.6356\n",
      "Epoch 24/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6490 - acc: 0.6160 - val_loss: 0.6236 - val_acc: 0.6433\n",
      "Epoch 25/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6444 - acc: 0.6280 - val_loss: 0.6219 - val_acc: 0.6589\n",
      "Epoch 26/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6546 - acc: 0.6210 - val_loss: 0.6201 - val_acc: 0.6667\n",
      "Epoch 27/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6462 - acc: 0.6236 - val_loss: 0.6182 - val_acc: 0.6722\n",
      "Epoch 28/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6523 - acc: 0.6296 - val_loss: 0.6169 - val_acc: 0.6733\n",
      "Epoch 29/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6420 - acc: 0.6359 - val_loss: 0.6155 - val_acc: 0.6778\n",
      "Epoch 30/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6394 - acc: 0.6374 - val_loss: 0.6138 - val_acc: 0.6822\n",
      "Epoch 31/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6387 - acc: 0.6325 - val_loss: 0.6125 - val_acc: 0.6889\n",
      "Epoch 32/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6397 - acc: 0.6395 - val_loss: 0.6109 - val_acc: 0.6900\n",
      "Epoch 33/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6332 - acc: 0.6446 - val_loss: 0.6095 - val_acc: 0.6944\n",
      "Epoch 34/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6354 - acc: 0.6477 - val_loss: 0.6080 - val_acc: 0.6967\n",
      "Epoch 35/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6320 - acc: 0.6473 - val_loss: 0.6062 - val_acc: 0.7044\n",
      "Epoch 36/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6307 - acc: 0.6495 - val_loss: 0.6049 - val_acc: 0.7044\n",
      "Epoch 37/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6326 - acc: 0.6546 - val_loss: 0.6034 - val_acc: 0.7111\n",
      "Epoch 38/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6257 - acc: 0.6604 - val_loss: 0.6019 - val_acc: 0.7111\n",
      "Epoch 39/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6253 - acc: 0.6649 - val_loss: 0.6002 - val_acc: 0.7200\n",
      "Epoch 40/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6250 - acc: 0.6636 - val_loss: 0.5988 - val_acc: 0.7244\n",
      "Epoch 41/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6164 - acc: 0.6726 - val_loss: 0.5973 - val_acc: 0.7267\n",
      "Epoch 42/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6219 - acc: 0.6663 - val_loss: 0.5959 - val_acc: 0.7311\n",
      "Epoch 43/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6185 - acc: 0.6684 - val_loss: 0.5944 - val_acc: 0.7389\n",
      "Epoch 44/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6124 - acc: 0.6811 - val_loss: 0.5929 - val_acc: 0.7389\n",
      "Epoch 45/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6216 - acc: 0.6740 - val_loss: 0.5914 - val_acc: 0.7367\n",
      "Epoch 46/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6162 - acc: 0.6767 - val_loss: 0.5902 - val_acc: 0.7389\n",
      "Epoch 47/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6089 - acc: 0.6790 - val_loss: 0.5889 - val_acc: 0.7411\n",
      "Epoch 48/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6076 - acc: 0.6807 - val_loss: 0.5877 - val_acc: 0.7456\n",
      "Epoch 49/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6127 - acc: 0.6833 - val_loss: 0.5865 - val_acc: 0.7478\n",
      "Epoch 50/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6077 - acc: 0.6858 - val_loss: 0.5852 - val_acc: 0.7511\n",
      "Epoch 51/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6067 - acc: 0.6893 - val_loss: 0.5839 - val_acc: 0.7511\n",
      "Epoch 52/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6071 - acc: 0.6875 - val_loss: 0.5825 - val_acc: 0.7522\n",
      "Epoch 53/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6065 - acc: 0.6923 - val_loss: 0.5811 - val_acc: 0.7578\n",
      "Epoch 54/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6053 - acc: 0.6880 - val_loss: 0.5799 - val_acc: 0.7578\n",
      "Epoch 55/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5950 - acc: 0.7027 - val_loss: 0.5786 - val_acc: 0.7589\n",
      "Epoch 56/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5987 - acc: 0.6940 - val_loss: 0.5773 - val_acc: 0.7611\n",
      "Epoch 57/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.6005 - acc: 0.6975 - val_loss: 0.5762 - val_acc: 0.7611\n",
      "Epoch 58/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5965 - acc: 0.7107 - val_loss: 0.5750 - val_acc: 0.7656\n",
      "Epoch 59/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5981 - acc: 0.7032 - val_loss: 0.5739 - val_acc: 0.7644\n",
      "Epoch 60/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5939 - acc: 0.6993 - val_loss: 0.5725 - val_acc: 0.7678\n",
      "Epoch 61/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5950 - acc: 0.7028 - val_loss: 0.5713 - val_acc: 0.7700\n",
      "Epoch 62/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5870 - acc: 0.7104 - val_loss: 0.5699 - val_acc: 0.7744\n",
      "Epoch 63/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5930 - acc: 0.7072 - val_loss: 0.5687 - val_acc: 0.7800\n",
      "Epoch 64/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5909 - acc: 0.7091 - val_loss: 0.5675 - val_acc: 0.7789\n",
      "Epoch 65/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5872 - acc: 0.7089 - val_loss: 0.5664 - val_acc: 0.7778\n",
      "Epoch 66/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5854 - acc: 0.7173 - val_loss: 0.5650 - val_acc: 0.7789\n",
      "Epoch 67/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5836 - acc: 0.7183 - val_loss: 0.5640 - val_acc: 0.7811\n",
      "Epoch 68/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5896 - acc: 0.7137 - val_loss: 0.5628 - val_acc: 0.7822\n",
      "Epoch 69/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5851 - acc: 0.7163 - val_loss: 0.5616 - val_acc: 0.7822\n",
      "Epoch 70/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5830 - acc: 0.7196 - val_loss: 0.5603 - val_acc: 0.7822\n",
      "Epoch 71/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5841 - acc: 0.7128 - val_loss: 0.5590 - val_acc: 0.7889\n",
      "Epoch 72/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5858 - acc: 0.7217 - val_loss: 0.5580 - val_acc: 0.7900\n",
      "Epoch 73/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5783 - acc: 0.7248 - val_loss: 0.5567 - val_acc: 0.7944\n",
      "Epoch 74/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5747 - acc: 0.7249 - val_loss: 0.5555 - val_acc: 0.7944\n",
      "Epoch 75/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5752 - acc: 0.7254 - val_loss: 0.5544 - val_acc: 0.7944\n",
      "Epoch 76/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5752 - acc: 0.7258 - val_loss: 0.5530 - val_acc: 0.7956\n",
      "Epoch 77/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5750 - acc: 0.7238 - val_loss: 0.5520 - val_acc: 0.7956\n",
      "Epoch 78/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5719 - acc: 0.7265 - val_loss: 0.5507 - val_acc: 0.8011\n",
      "Epoch 79/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5756 - acc: 0.7201 - val_loss: 0.5496 - val_acc: 0.7989\n",
      "Epoch 80/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5772 - acc: 0.7279 - val_loss: 0.5484 - val_acc: 0.8011\n",
      "Epoch 81/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5658 - acc: 0.7362 - val_loss: 0.5474 - val_acc: 0.8011\n",
      "Epoch 82/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5723 - acc: 0.7263 - val_loss: 0.5464 - val_acc: 0.8011\n",
      "Epoch 83/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5665 - acc: 0.7352 - val_loss: 0.5453 - val_acc: 0.8022\n",
      "Epoch 84/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5618 - acc: 0.7370 - val_loss: 0.5443 - val_acc: 0.8033\n",
      "Epoch 85/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5674 - acc: 0.7342 - val_loss: 0.5430 - val_acc: 0.8011\n",
      "Epoch 86/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5643 - acc: 0.7365 - val_loss: 0.5419 - val_acc: 0.8011\n",
      "Epoch 87/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5594 - acc: 0.7360 - val_loss: 0.5409 - val_acc: 0.8022\n",
      "Epoch 88/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5593 - acc: 0.7398 - val_loss: 0.5399 - val_acc: 0.8022\n",
      "Epoch 89/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5571 - acc: 0.7372 - val_loss: 0.5387 - val_acc: 0.8011\n",
      "Epoch 90/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5598 - acc: 0.7348 - val_loss: 0.5375 - val_acc: 0.8022\n",
      "Epoch 91/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5615 - acc: 0.7375 - val_loss: 0.5363 - val_acc: 0.8022\n",
      "Epoch 92/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5575 - acc: 0.7400 - val_loss: 0.5352 - val_acc: 0.8033\n",
      "Epoch 93/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5566 - acc: 0.7389 - val_loss: 0.5342 - val_acc: 0.8033\n",
      "Epoch 94/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5564 - acc: 0.7435 - val_loss: 0.5330 - val_acc: 0.8011\n",
      "Epoch 95/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5560 - acc: 0.7433 - val_loss: 0.5320 - val_acc: 0.8011\n",
      "Epoch 96/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5551 - acc: 0.7444 - val_loss: 0.5309 - val_acc: 0.8022\n",
      "Epoch 97/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5497 - acc: 0.7483 - val_loss: 0.5299 - val_acc: 0.8033\n",
      "Epoch 98/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5525 - acc: 0.7491 - val_loss: 0.5287 - val_acc: 0.8022\n",
      "Epoch 99/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5511 - acc: 0.7410 - val_loss: 0.5276 - val_acc: 0.8022\n",
      "Epoch 100/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5500 - acc: 0.7347 - val_loss: 0.5265 - val_acc: 0.8022\n",
      "Epoch 101/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5528 - acc: 0.7411 - val_loss: 0.5254 - val_acc: 0.8033\n",
      "Epoch 102/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5468 - acc: 0.7536 - val_loss: 0.5244 - val_acc: 0.8033\n",
      "Epoch 103/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5475 - acc: 0.7447 - val_loss: 0.5234 - val_acc: 0.8033\n",
      "Epoch 104/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5450 - acc: 0.7521 - val_loss: 0.5224 - val_acc: 0.8022\n",
      "Epoch 105/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5453 - acc: 0.7504 - val_loss: 0.5214 - val_acc: 0.8022\n",
      "Epoch 106/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5457 - acc: 0.7498 - val_loss: 0.5203 - val_acc: 0.8044\n",
      "Epoch 107/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5414 - acc: 0.7567 - val_loss: 0.5192 - val_acc: 0.8067\n",
      "Epoch 108/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5460 - acc: 0.7498 - val_loss: 0.5180 - val_acc: 0.8089\n",
      "Epoch 109/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5404 - acc: 0.7589 - val_loss: 0.5169 - val_acc: 0.8100\n",
      "Epoch 110/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5413 - acc: 0.7504 - val_loss: 0.5159 - val_acc: 0.8100\n",
      "Epoch 111/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5381 - acc: 0.7465 - val_loss: 0.5149 - val_acc: 0.8089\n",
      "Epoch 112/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5380 - acc: 0.7573 - val_loss: 0.5139 - val_acc: 0.8078\n",
      "Epoch 113/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5419 - acc: 0.7493 - val_loss: 0.5128 - val_acc: 0.8078\n",
      "Epoch 114/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5335 - acc: 0.7560 - val_loss: 0.5120 - val_acc: 0.8078\n",
      "Epoch 115/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5304 - acc: 0.7538 - val_loss: 0.5109 - val_acc: 0.8089\n",
      "Epoch 116/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5340 - acc: 0.7577 - val_loss: 0.5100 - val_acc: 0.8089\n",
      "Epoch 117/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5308 - acc: 0.7553 - val_loss: 0.5091 - val_acc: 0.8089\n",
      "Epoch 118/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5294 - acc: 0.7604 - val_loss: 0.5082 - val_acc: 0.8100\n",
      "Epoch 119/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5336 - acc: 0.7588 - val_loss: 0.5071 - val_acc: 0.8100\n",
      "Epoch 120/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5290 - acc: 0.7585 - val_loss: 0.5061 - val_acc: 0.8089\n",
      "Epoch 121/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5286 - acc: 0.7643 - val_loss: 0.5050 - val_acc: 0.8122\n",
      "Epoch 122/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5218 - acc: 0.7693 - val_loss: 0.5041 - val_acc: 0.8122\n",
      "Epoch 123/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5304 - acc: 0.7590 - val_loss: 0.5032 - val_acc: 0.8122\n",
      "Epoch 124/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5257 - acc: 0.7604 - val_loss: 0.5022 - val_acc: 0.8111\n",
      "Epoch 125/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5275 - acc: 0.7628 - val_loss: 0.5011 - val_acc: 0.8111\n",
      "Epoch 126/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5231 - acc: 0.7606 - val_loss: 0.5001 - val_acc: 0.8122\n",
      "Epoch 127/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5217 - acc: 0.7643 - val_loss: 0.4992 - val_acc: 0.8122\n",
      "Epoch 128/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5232 - acc: 0.7628 - val_loss: 0.4983 - val_acc: 0.8122\n",
      "Epoch 129/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5210 - acc: 0.7615 - val_loss: 0.4973 - val_acc: 0.8122\n",
      "Epoch 130/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5237 - acc: 0.7564 - val_loss: 0.4964 - val_acc: 0.8122\n",
      "Epoch 131/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5243 - acc: 0.7674 - val_loss: 0.4954 - val_acc: 0.8122\n",
      "Epoch 132/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5206 - acc: 0.7619 - val_loss: 0.4945 - val_acc: 0.8122\n",
      "Epoch 133/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5183 - acc: 0.7627 - val_loss: 0.4937 - val_acc: 0.8122\n",
      "Epoch 134/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5188 - acc: 0.7662 - val_loss: 0.4926 - val_acc: 0.8156\n",
      "Epoch 135/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5231 - acc: 0.7662 - val_loss: 0.4916 - val_acc: 0.8156\n",
      "Epoch 136/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5203 - acc: 0.7709 - val_loss: 0.4905 - val_acc: 0.8156\n",
      "Epoch 137/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5187 - acc: 0.7641 - val_loss: 0.4896 - val_acc: 0.8167\n",
      "Epoch 138/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5137 - acc: 0.7628 - val_loss: 0.4887 - val_acc: 0.8167\n",
      "Epoch 139/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5151 - acc: 0.7664 - val_loss: 0.4879 - val_acc: 0.8167\n",
      "Epoch 140/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5187 - acc: 0.7654 - val_loss: 0.4870 - val_acc: 0.8167\n",
      "Epoch 141/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5160 - acc: 0.7694 - val_loss: 0.4862 - val_acc: 0.8167\n",
      "Epoch 142/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5116 - acc: 0.7699 - val_loss: 0.4851 - val_acc: 0.8167\n",
      "Epoch 143/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5139 - acc: 0.7689 - val_loss: 0.4843 - val_acc: 0.8167\n",
      "Epoch 144/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5142 - acc: 0.7696 - val_loss: 0.4835 - val_acc: 0.8178\n",
      "Epoch 145/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5095 - acc: 0.7683 - val_loss: 0.4828 - val_acc: 0.8178\n",
      "Epoch 146/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5146 - acc: 0.7656 - val_loss: 0.4819 - val_acc: 0.8189\n",
      "Epoch 147/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5069 - acc: 0.7714 - val_loss: 0.4812 - val_acc: 0.8189\n",
      "Epoch 148/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5090 - acc: 0.7715 - val_loss: 0.4802 - val_acc: 0.8222\n",
      "Epoch 149/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5080 - acc: 0.7757 - val_loss: 0.4793 - val_acc: 0.8222\n",
      "Epoch 150/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4972 - acc: 0.7757 - val_loss: 0.4784 - val_acc: 0.8233\n",
      "Epoch 151/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5072 - acc: 0.7702 - val_loss: 0.4776 - val_acc: 0.8244\n",
      "Epoch 152/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4987 - acc: 0.7764 - val_loss: 0.4771 - val_acc: 0.8244\n",
      "Epoch 153/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5010 - acc: 0.7781 - val_loss: 0.4762 - val_acc: 0.8256\n",
      "Epoch 154/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5036 - acc: 0.7817 - val_loss: 0.4751 - val_acc: 0.8267\n",
      "Epoch 155/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4901 - acc: 0.7837 - val_loss: 0.4743 - val_acc: 0.8278\n",
      "Epoch 156/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.5065 - acc: 0.7700 - val_loss: 0.4735 - val_acc: 0.8278\n",
      "Epoch 157/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4947 - acc: 0.7827 - val_loss: 0.4725 - val_acc: 0.8289\n",
      "Epoch 158/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4979 - acc: 0.7786 - val_loss: 0.4717 - val_acc: 0.8289\n",
      "Epoch 159/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4960 - acc: 0.7814 - val_loss: 0.4709 - val_acc: 0.8300\n",
      "Epoch 160/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4916 - acc: 0.7843 - val_loss: 0.4700 - val_acc: 0.8300\n",
      "Epoch 161/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4974 - acc: 0.7740 - val_loss: 0.4692 - val_acc: 0.8289\n",
      "Epoch 162/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4931 - acc: 0.7765 - val_loss: 0.4683 - val_acc: 0.8300\n",
      "Epoch 163/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4975 - acc: 0.7785 - val_loss: 0.4674 - val_acc: 0.8300\n",
      "Epoch 164/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4906 - acc: 0.7791 - val_loss: 0.4666 - val_acc: 0.8300\n",
      "Epoch 165/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4926 - acc: 0.7748 - val_loss: 0.4658 - val_acc: 0.8311\n",
      "Epoch 166/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4936 - acc: 0.7765 - val_loss: 0.4648 - val_acc: 0.8322\n",
      "Epoch 167/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4864 - acc: 0.7830 - val_loss: 0.4640 - val_acc: 0.8322\n",
      "Epoch 168/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4817 - acc: 0.7880 - val_loss: 0.4632 - val_acc: 0.8333\n",
      "Epoch 169/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4910 - acc: 0.7805 - val_loss: 0.4625 - val_acc: 0.8356\n",
      "Epoch 170/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4951 - acc: 0.7793 - val_loss: 0.4618 - val_acc: 0.8344\n",
      "Epoch 171/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4870 - acc: 0.7821 - val_loss: 0.4610 - val_acc: 0.8344\n",
      "Epoch 172/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4906 - acc: 0.7836 - val_loss: 0.4602 - val_acc: 0.8367\n",
      "Epoch 173/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4846 - acc: 0.7854 - val_loss: 0.4596 - val_acc: 0.8367\n",
      "Epoch 174/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4886 - acc: 0.7836 - val_loss: 0.4588 - val_acc: 0.8367\n",
      "Epoch 175/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4867 - acc: 0.7826 - val_loss: 0.4578 - val_acc: 0.8367\n",
      "Epoch 176/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4862 - acc: 0.7854 - val_loss: 0.4570 - val_acc: 0.8367\n",
      "Epoch 177/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4814 - acc: 0.7888 - val_loss: 0.4563 - val_acc: 0.8367\n",
      "Epoch 178/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4815 - acc: 0.7841 - val_loss: 0.4554 - val_acc: 0.8367\n",
      "Epoch 179/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4847 - acc: 0.7877 - val_loss: 0.4548 - val_acc: 0.8367\n",
      "Epoch 180/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4813 - acc: 0.7833 - val_loss: 0.4541 - val_acc: 0.8367\n",
      "Epoch 181/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4890 - acc: 0.7819 - val_loss: 0.4533 - val_acc: 0.8367\n",
      "Epoch 182/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4750 - acc: 0.7896 - val_loss: 0.4522 - val_acc: 0.8356\n",
      "Epoch 183/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4796 - acc: 0.7881 - val_loss: 0.4515 - val_acc: 0.8356\n",
      "Epoch 184/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4766 - acc: 0.7921 - val_loss: 0.4508 - val_acc: 0.8356\n",
      "Epoch 185/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4715 - acc: 0.7920 - val_loss: 0.4499 - val_acc: 0.8367\n",
      "Epoch 186/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4753 - acc: 0.7891 - val_loss: 0.4492 - val_acc: 0.8367\n",
      "Epoch 187/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4806 - acc: 0.7865 - val_loss: 0.4484 - val_acc: 0.8378\n",
      "Epoch 188/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4739 - acc: 0.7920 - val_loss: 0.4476 - val_acc: 0.8378\n",
      "Epoch 189/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4718 - acc: 0.7891 - val_loss: 0.4470 - val_acc: 0.8378\n",
      "Epoch 190/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4771 - acc: 0.7849 - val_loss: 0.4462 - val_acc: 0.8389\n",
      "Epoch 191/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4700 - acc: 0.7936 - val_loss: 0.4454 - val_acc: 0.8389\n",
      "Epoch 192/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4732 - acc: 0.7853 - val_loss: 0.4446 - val_acc: 0.8389\n",
      "Epoch 193/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4703 - acc: 0.7902 - val_loss: 0.4440 - val_acc: 0.8389\n",
      "Epoch 194/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4745 - acc: 0.7886 - val_loss: 0.4432 - val_acc: 0.8411\n",
      "Epoch 195/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4699 - acc: 0.7959 - val_loss: 0.4423 - val_acc: 0.8411\n",
      "Epoch 196/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4750 - acc: 0.7900 - val_loss: 0.4414 - val_acc: 0.8411\n",
      "Epoch 197/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4638 - acc: 0.7930 - val_loss: 0.4412 - val_acc: 0.8433\n",
      "Epoch 198/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4707 - acc: 0.7899 - val_loss: 0.4406 - val_acc: 0.8444\n",
      "Epoch 199/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4745 - acc: 0.7910 - val_loss: 0.4400 - val_acc: 0.8444\n",
      "Epoch 200/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4697 - acc: 0.7909 - val_loss: 0.4391 - val_acc: 0.8433\n",
      "Epoch 201/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4645 - acc: 0.7956 - val_loss: 0.4383 - val_acc: 0.8433\n",
      "Epoch 202/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4700 - acc: 0.7867 - val_loss: 0.4375 - val_acc: 0.8433\n",
      "Epoch 203/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4633 - acc: 0.7940 - val_loss: 0.4369 - val_acc: 0.8433\n",
      "Epoch 204/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4696 - acc: 0.7978 - val_loss: 0.4361 - val_acc: 0.8433\n",
      "Epoch 205/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4692 - acc: 0.8015 - val_loss: 0.4352 - val_acc: 0.8433\n",
      "Epoch 206/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4698 - acc: 0.7937 - val_loss: 0.4344 - val_acc: 0.8433\n",
      "Epoch 207/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4620 - acc: 0.7981 - val_loss: 0.4338 - val_acc: 0.8433\n",
      "Epoch 208/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4577 - acc: 0.8001 - val_loss: 0.4333 - val_acc: 0.8433\n",
      "Epoch 209/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4621 - acc: 0.7972 - val_loss: 0.4325 - val_acc: 0.8433\n",
      "Epoch 210/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4624 - acc: 0.7940 - val_loss: 0.4317 - val_acc: 0.8444\n",
      "Epoch 211/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4583 - acc: 0.7984 - val_loss: 0.4311 - val_acc: 0.8444\n",
      "Epoch 212/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4554 - acc: 0.7959 - val_loss: 0.4306 - val_acc: 0.8444\n",
      "Epoch 213/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4506 - acc: 0.8056 - val_loss: 0.4302 - val_acc: 0.8456\n",
      "Epoch 214/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4620 - acc: 0.7946 - val_loss: 0.4292 - val_acc: 0.8456\n",
      "Epoch 215/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4510 - acc: 0.8009 - val_loss: 0.4285 - val_acc: 0.8456\n",
      "Epoch 216/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4570 - acc: 0.7981 - val_loss: 0.4276 - val_acc: 0.8478\n",
      "Epoch 217/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4557 - acc: 0.7983 - val_loss: 0.4272 - val_acc: 0.8467\n",
      "Epoch 218/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4541 - acc: 0.7974 - val_loss: 0.4267 - val_acc: 0.8456\n",
      "Epoch 219/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4548 - acc: 0.8011 - val_loss: 0.4260 - val_acc: 0.8456\n",
      "Epoch 220/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4531 - acc: 0.8030 - val_loss: 0.4255 - val_acc: 0.8444\n",
      "Epoch 221/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4616 - acc: 0.7973 - val_loss: 0.4248 - val_acc: 0.8444\n",
      "Epoch 222/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4554 - acc: 0.8014 - val_loss: 0.4241 - val_acc: 0.8456\n",
      "Epoch 223/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4557 - acc: 0.8010 - val_loss: 0.4235 - val_acc: 0.8467\n",
      "Epoch 224/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4446 - acc: 0.8074 - val_loss: 0.4227 - val_acc: 0.8467\n",
      "Epoch 225/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4478 - acc: 0.8089 - val_loss: 0.4220 - val_acc: 0.8467\n",
      "Epoch 226/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4486 - acc: 0.8020 - val_loss: 0.4214 - val_acc: 0.8456\n",
      "Epoch 227/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4547 - acc: 0.8023 - val_loss: 0.4207 - val_acc: 0.8456\n",
      "Epoch 228/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4436 - acc: 0.8051 - val_loss: 0.4202 - val_acc: 0.8433\n",
      "Epoch 229/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4489 - acc: 0.8043 - val_loss: 0.4192 - val_acc: 0.8444\n",
      "Epoch 230/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4552 - acc: 0.7985 - val_loss: 0.4186 - val_acc: 0.8467\n",
      "Epoch 231/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4485 - acc: 0.8014 - val_loss: 0.4179 - val_acc: 0.8467\n",
      "Epoch 232/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4568 - acc: 0.7957 - val_loss: 0.4172 - val_acc: 0.8467\n",
      "Epoch 233/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4516 - acc: 0.8035 - val_loss: 0.4167 - val_acc: 0.8478\n",
      "Epoch 234/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4465 - acc: 0.8020 - val_loss: 0.4160 - val_acc: 0.8478\n",
      "Epoch 235/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4448 - acc: 0.8105 - val_loss: 0.4152 - val_acc: 0.8467\n",
      "Epoch 236/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4482 - acc: 0.8011 - val_loss: 0.4146 - val_acc: 0.8467\n",
      "Epoch 237/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4424 - acc: 0.8043 - val_loss: 0.4140 - val_acc: 0.8467\n",
      "Epoch 238/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4484 - acc: 0.8020 - val_loss: 0.4135 - val_acc: 0.8467\n",
      "Epoch 239/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4461 - acc: 0.8037 - val_loss: 0.4128 - val_acc: 0.8467\n",
      "Epoch 240/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4446 - acc: 0.8069 - val_loss: 0.4120 - val_acc: 0.8478\n",
      "Epoch 241/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4413 - acc: 0.8106 - val_loss: 0.4113 - val_acc: 0.8489\n",
      "Epoch 242/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4416 - acc: 0.8065 - val_loss: 0.4107 - val_acc: 0.8489\n",
      "Epoch 243/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4342 - acc: 0.8125 - val_loss: 0.4101 - val_acc: 0.8489\n",
      "Epoch 244/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4405 - acc: 0.8078 - val_loss: 0.4095 - val_acc: 0.8500\n",
      "Epoch 245/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4416 - acc: 0.8084 - val_loss: 0.4091 - val_acc: 0.8500\n",
      "Epoch 246/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4385 - acc: 0.8044 - val_loss: 0.4084 - val_acc: 0.8500\n",
      "Epoch 247/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4334 - acc: 0.8101 - val_loss: 0.4079 - val_acc: 0.8511\n",
      "Epoch 248/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4412 - acc: 0.8112 - val_loss: 0.4073 - val_acc: 0.8500\n",
      "Epoch 249/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4449 - acc: 0.8044 - val_loss: 0.4066 - val_acc: 0.8500\n",
      "Epoch 250/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4402 - acc: 0.8077 - val_loss: 0.4058 - val_acc: 0.8511\n",
      "Epoch 251/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4375 - acc: 0.8107 - val_loss: 0.4052 - val_acc: 0.8522\n",
      "Epoch 252/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4293 - acc: 0.8115 - val_loss: 0.4049 - val_acc: 0.8533\n",
      "Epoch 253/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4356 - acc: 0.8110 - val_loss: 0.4041 - val_acc: 0.8522\n",
      "Epoch 254/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4298 - acc: 0.8167 - val_loss: 0.4033 - val_acc: 0.8522\n",
      "Epoch 255/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4363 - acc: 0.8095 - val_loss: 0.4025 - val_acc: 0.8533\n",
      "Epoch 256/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4379 - acc: 0.8122 - val_loss: 0.4019 - val_acc: 0.8522\n",
      "Epoch 257/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4311 - acc: 0.8115 - val_loss: 0.4016 - val_acc: 0.8522\n",
      "Epoch 258/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4369 - acc: 0.8101 - val_loss: 0.4009 - val_acc: 0.8511\n",
      "Epoch 259/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4336 - acc: 0.8123 - val_loss: 0.4002 - val_acc: 0.8522\n",
      "Epoch 260/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4301 - acc: 0.8126 - val_loss: 0.3998 - val_acc: 0.8522\n",
      "Epoch 261/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4311 - acc: 0.8120 - val_loss: 0.3992 - val_acc: 0.8533\n",
      "Epoch 262/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4290 - acc: 0.8177 - val_loss: 0.3985 - val_acc: 0.8533\n",
      "Epoch 263/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4309 - acc: 0.8169 - val_loss: 0.3978 - val_acc: 0.8544\n",
      "Epoch 264/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4232 - acc: 0.8131 - val_loss: 0.3970 - val_acc: 0.8556\n",
      "Epoch 265/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4240 - acc: 0.8194 - val_loss: 0.3961 - val_acc: 0.8578\n",
      "Epoch 266/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4251 - acc: 0.8151 - val_loss: 0.3956 - val_acc: 0.8578\n",
      "Epoch 267/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4226 - acc: 0.8132 - val_loss: 0.3952 - val_acc: 0.8578\n",
      "Epoch 268/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4226 - acc: 0.8174 - val_loss: 0.3947 - val_acc: 0.8578\n",
      "Epoch 269/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4259 - acc: 0.8096 - val_loss: 0.3942 - val_acc: 0.8578\n",
      "Epoch 270/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4242 - acc: 0.8164 - val_loss: 0.3939 - val_acc: 0.8567\n",
      "Epoch 271/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4244 - acc: 0.8164 - val_loss: 0.3935 - val_acc: 0.8578\n",
      "Epoch 272/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4226 - acc: 0.8199 - val_loss: 0.3930 - val_acc: 0.8589\n",
      "Epoch 273/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4224 - acc: 0.8138 - val_loss: 0.3925 - val_acc: 0.8589\n",
      "Epoch 274/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4191 - acc: 0.8200 - val_loss: 0.3921 - val_acc: 0.8589\n",
      "Epoch 275/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4189 - acc: 0.8174 - val_loss: 0.3913 - val_acc: 0.8589\n",
      "Epoch 276/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4208 - acc: 0.8198 - val_loss: 0.3909 - val_acc: 0.8600\n",
      "Epoch 277/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4190 - acc: 0.8217 - val_loss: 0.3901 - val_acc: 0.8600\n",
      "Epoch 278/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4221 - acc: 0.8142 - val_loss: 0.3897 - val_acc: 0.8600\n",
      "Epoch 279/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4188 - acc: 0.8226 - val_loss: 0.3893 - val_acc: 0.8611\n",
      "Epoch 280/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4181 - acc: 0.8195 - val_loss: 0.3887 - val_acc: 0.8622\n",
      "Epoch 281/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4216 - acc: 0.8232 - val_loss: 0.3880 - val_acc: 0.8622\n",
      "Epoch 282/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4117 - acc: 0.8204 - val_loss: 0.3873 - val_acc: 0.8622\n",
      "Epoch 283/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4193 - acc: 0.8205 - val_loss: 0.3868 - val_acc: 0.8611\n",
      "Epoch 284/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4184 - acc: 0.8217 - val_loss: 0.3859 - val_acc: 0.8600\n",
      "Epoch 285/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4196 - acc: 0.8172 - val_loss: 0.3853 - val_acc: 0.8600\n",
      "Epoch 286/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4163 - acc: 0.8228 - val_loss: 0.3847 - val_acc: 0.8600\n",
      "Epoch 287/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4176 - acc: 0.8111 - val_loss: 0.3841 - val_acc: 0.8600\n",
      "Epoch 288/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4087 - acc: 0.8257 - val_loss: 0.3836 - val_acc: 0.8589\n",
      "Epoch 289/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4140 - acc: 0.8209 - val_loss: 0.3829 - val_acc: 0.8589\n",
      "Epoch 290/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4126 - acc: 0.8262 - val_loss: 0.3823 - val_acc: 0.8589\n",
      "Epoch 291/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4111 - acc: 0.8209 - val_loss: 0.3819 - val_acc: 0.8600\n",
      "Epoch 292/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4162 - acc: 0.8202 - val_loss: 0.3816 - val_acc: 0.8622\n",
      "Epoch 293/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4154 - acc: 0.8246 - val_loss: 0.3810 - val_acc: 0.8644\n",
      "Epoch 294/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4141 - acc: 0.8194 - val_loss: 0.3806 - val_acc: 0.8644\n",
      "Epoch 295/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4077 - acc: 0.8223 - val_loss: 0.3801 - val_acc: 0.8644\n",
      "Epoch 296/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4133 - acc: 0.8209 - val_loss: 0.3795 - val_acc: 0.8667\n",
      "Epoch 297/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4059 - acc: 0.8253 - val_loss: 0.3788 - val_acc: 0.8656\n",
      "Epoch 298/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4036 - acc: 0.8249 - val_loss: 0.3782 - val_acc: 0.8656\n",
      "Epoch 299/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4103 - acc: 0.8200 - val_loss: 0.3776 - val_acc: 0.8656\n",
      "Epoch 300/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4055 - acc: 0.8243 - val_loss: 0.3768 - val_acc: 0.8656\n",
      "Epoch 301/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4104 - acc: 0.8220 - val_loss: 0.3765 - val_acc: 0.8656\n",
      "Epoch 302/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4064 - acc: 0.8252 - val_loss: 0.3759 - val_acc: 0.8656\n",
      "Epoch 303/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4041 - acc: 0.8252 - val_loss: 0.3756 - val_acc: 0.8656\n",
      "Epoch 304/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4107 - acc: 0.8215 - val_loss: 0.3751 - val_acc: 0.8656\n",
      "Epoch 305/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4040 - acc: 0.8270 - val_loss: 0.3745 - val_acc: 0.8667\n",
      "Epoch 306/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4079 - acc: 0.8265 - val_loss: 0.3739 - val_acc: 0.8667\n",
      "Epoch 307/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4108 - acc: 0.8278 - val_loss: 0.3732 - val_acc: 0.8667\n",
      "Epoch 308/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4048 - acc: 0.8286 - val_loss: 0.3730 - val_acc: 0.8667\n",
      "Epoch 309/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3991 - acc: 0.8322 - val_loss: 0.3726 - val_acc: 0.8678\n",
      "Epoch 310/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4019 - acc: 0.8196 - val_loss: 0.3721 - val_acc: 0.8678\n",
      "Epoch 311/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4039 - acc: 0.8264 - val_loss: 0.3716 - val_acc: 0.8678\n",
      "Epoch 312/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4020 - acc: 0.8246 - val_loss: 0.3710 - val_acc: 0.8678\n",
      "Epoch 313/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4019 - acc: 0.8284 - val_loss: 0.3703 - val_acc: 0.8678\n",
      "Epoch 314/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4042 - acc: 0.8277 - val_loss: 0.3694 - val_acc: 0.8689\n",
      "Epoch 315/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4052 - acc: 0.8301 - val_loss: 0.3691 - val_acc: 0.8678\n",
      "Epoch 316/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4029 - acc: 0.8233 - val_loss: 0.3685 - val_acc: 0.8678\n",
      "Epoch 317/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3953 - acc: 0.8299 - val_loss: 0.3677 - val_acc: 0.8689\n",
      "Epoch 318/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4024 - acc: 0.8307 - val_loss: 0.3672 - val_acc: 0.8689\n",
      "Epoch 319/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3976 - acc: 0.8278 - val_loss: 0.3667 - val_acc: 0.8689\n",
      "Epoch 320/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.4010 - acc: 0.8277 - val_loss: 0.3664 - val_acc: 0.8689\n",
      "Epoch 321/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3949 - acc: 0.8294 - val_loss: 0.3658 - val_acc: 0.8700\n",
      "Epoch 322/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3981 - acc: 0.8284 - val_loss: 0.3654 - val_acc: 0.8700\n",
      "Epoch 323/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3950 - acc: 0.8328 - val_loss: 0.3649 - val_acc: 0.8700\n",
      "Epoch 324/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3914 - acc: 0.8311 - val_loss: 0.3646 - val_acc: 0.8700\n",
      "Epoch 325/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3983 - acc: 0.8337 - val_loss: 0.3643 - val_acc: 0.8711\n",
      "Epoch 326/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3913 - acc: 0.8367 - val_loss: 0.3636 - val_acc: 0.8711\n",
      "Epoch 327/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3952 - acc: 0.8319 - val_loss: 0.3629 - val_acc: 0.8711\n",
      "Epoch 328/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3951 - acc: 0.8327 - val_loss: 0.3622 - val_acc: 0.8711\n",
      "Epoch 329/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3849 - acc: 0.8367 - val_loss: 0.3619 - val_acc: 0.8711\n",
      "Epoch 330/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3977 - acc: 0.8348 - val_loss: 0.3614 - val_acc: 0.8711\n",
      "Epoch 331/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3947 - acc: 0.8360 - val_loss: 0.3608 - val_acc: 0.8711\n",
      "Epoch 332/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3936 - acc: 0.8270 - val_loss: 0.3602 - val_acc: 0.8711\n",
      "Epoch 333/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3906 - acc: 0.8343 - val_loss: 0.3596 - val_acc: 0.8711\n",
      "Epoch 334/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3924 - acc: 0.8309 - val_loss: 0.3591 - val_acc: 0.8711\n",
      "Epoch 335/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3797 - acc: 0.8405 - val_loss: 0.3586 - val_acc: 0.8711\n",
      "Epoch 336/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3943 - acc: 0.8322 - val_loss: 0.3584 - val_acc: 0.8722\n",
      "Epoch 337/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3920 - acc: 0.8399 - val_loss: 0.3578 - val_acc: 0.8722\n",
      "Epoch 338/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3899 - acc: 0.8333 - val_loss: 0.3573 - val_acc: 0.8722\n",
      "Epoch 339/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3908 - acc: 0.8336 - val_loss: 0.3569 - val_acc: 0.8722\n",
      "Epoch 340/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3893 - acc: 0.8335 - val_loss: 0.3567 - val_acc: 0.8733\n",
      "Epoch 341/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3896 - acc: 0.8343 - val_loss: 0.3561 - val_acc: 0.8733\n",
      "Epoch 342/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3879 - acc: 0.8328 - val_loss: 0.3554 - val_acc: 0.8722\n",
      "Epoch 343/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3888 - acc: 0.8333 - val_loss: 0.3550 - val_acc: 0.8722\n",
      "Epoch 344/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3863 - acc: 0.8359 - val_loss: 0.3546 - val_acc: 0.8722\n",
      "Epoch 345/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3820 - acc: 0.8379 - val_loss: 0.3541 - val_acc: 0.8722\n",
      "Epoch 346/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3790 - acc: 0.8410 - val_loss: 0.3536 - val_acc: 0.8722\n",
      "Epoch 347/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3850 - acc: 0.8365 - val_loss: 0.3529 - val_acc: 0.8722\n",
      "Epoch 348/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3793 - acc: 0.8383 - val_loss: 0.3527 - val_acc: 0.8722\n",
      "Epoch 349/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3870 - acc: 0.8380 - val_loss: 0.3523 - val_acc: 0.8722\n",
      "Epoch 350/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3753 - acc: 0.8409 - val_loss: 0.3522 - val_acc: 0.8733\n",
      "Epoch 351/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3780 - acc: 0.8374 - val_loss: 0.3518 - val_acc: 0.8744\n",
      "Epoch 352/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3801 - acc: 0.8398 - val_loss: 0.3513 - val_acc: 0.8744\n",
      "Epoch 353/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3805 - acc: 0.8375 - val_loss: 0.3510 - val_acc: 0.8744\n",
      "Epoch 354/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3805 - acc: 0.8414 - val_loss: 0.3503 - val_acc: 0.8744\n",
      "Epoch 355/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3763 - acc: 0.8399 - val_loss: 0.3499 - val_acc: 0.8744\n",
      "Epoch 356/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3836 - acc: 0.8368 - val_loss: 0.3490 - val_acc: 0.8744\n",
      "Epoch 357/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3833 - acc: 0.8410 - val_loss: 0.3483 - val_acc: 0.8722\n",
      "Epoch 358/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3796 - acc: 0.8423 - val_loss: 0.3478 - val_acc: 0.8722\n",
      "Epoch 359/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3815 - acc: 0.8393 - val_loss: 0.3472 - val_acc: 0.8722\n",
      "Epoch 360/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3820 - acc: 0.8389 - val_loss: 0.3467 - val_acc: 0.8722\n",
      "Epoch 361/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3774 - acc: 0.8421 - val_loss: 0.3462 - val_acc: 0.8722\n",
      "Epoch 362/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3731 - acc: 0.8484 - val_loss: 0.3459 - val_acc: 0.8733\n",
      "Epoch 363/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3772 - acc: 0.8356 - val_loss: 0.3453 - val_acc: 0.8722\n",
      "Epoch 364/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3722 - acc: 0.8419 - val_loss: 0.3449 - val_acc: 0.8722\n",
      "Epoch 365/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3714 - acc: 0.8447 - val_loss: 0.3447 - val_acc: 0.8744\n",
      "Epoch 366/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3683 - acc: 0.8428 - val_loss: 0.3444 - val_acc: 0.8744\n",
      "Epoch 367/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3776 - acc: 0.8368 - val_loss: 0.3440 - val_acc: 0.8744\n",
      "Epoch 368/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3733 - acc: 0.8384 - val_loss: 0.3435 - val_acc: 0.8744\n",
      "Epoch 369/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3710 - acc: 0.8426 - val_loss: 0.3430 - val_acc: 0.8744\n",
      "Epoch 370/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3794 - acc: 0.8385 - val_loss: 0.3425 - val_acc: 0.8744\n",
      "Epoch 371/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3744 - acc: 0.8411 - val_loss: 0.3423 - val_acc: 0.8744\n",
      "Epoch 372/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3760 - acc: 0.8405 - val_loss: 0.3420 - val_acc: 0.8744\n",
      "Epoch 373/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3704 - acc: 0.8431 - val_loss: 0.3410 - val_acc: 0.8733\n",
      "Epoch 374/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3805 - acc: 0.8368 - val_loss: 0.3407 - val_acc: 0.8744\n",
      "Epoch 375/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3720 - acc: 0.8446 - val_loss: 0.3405 - val_acc: 0.8744\n",
      "Epoch 376/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3681 - acc: 0.8451 - val_loss: 0.3398 - val_acc: 0.8744\n",
      "Epoch 377/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3715 - acc: 0.8449 - val_loss: 0.3393 - val_acc: 0.8744\n",
      "Epoch 378/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3669 - acc: 0.8479 - val_loss: 0.3390 - val_acc: 0.8744\n",
      "Epoch 379/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3693 - acc: 0.8507 - val_loss: 0.3385 - val_acc: 0.8744\n",
      "Epoch 380/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3737 - acc: 0.8449 - val_loss: 0.3381 - val_acc: 0.8756\n",
      "Epoch 381/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3655 - acc: 0.8495 - val_loss: 0.3377 - val_acc: 0.8756\n",
      "Epoch 382/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3708 - acc: 0.8457 - val_loss: 0.3372 - val_acc: 0.8744\n",
      "Epoch 383/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3689 - acc: 0.8440 - val_loss: 0.3368 - val_acc: 0.8744\n",
      "Epoch 384/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3660 - acc: 0.8443 - val_loss: 0.3366 - val_acc: 0.8756\n",
      "Epoch 385/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3639 - acc: 0.8485 - val_loss: 0.3361 - val_acc: 0.8744\n",
      "Epoch 386/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3670 - acc: 0.8475 - val_loss: 0.3355 - val_acc: 0.8744\n",
      "Epoch 387/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3594 - acc: 0.8506 - val_loss: 0.3352 - val_acc: 0.8744\n",
      "Epoch 388/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3585 - acc: 0.8500 - val_loss: 0.3349 - val_acc: 0.8756\n",
      "Epoch 389/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3661 - acc: 0.8422 - val_loss: 0.3346 - val_acc: 0.8767\n",
      "Epoch 390/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3544 - acc: 0.8499 - val_loss: 0.3343 - val_acc: 0.8778\n",
      "Epoch 391/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3608 - acc: 0.8477 - val_loss: 0.3338 - val_acc: 0.8778\n",
      "Epoch 392/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3608 - acc: 0.8494 - val_loss: 0.3334 - val_acc: 0.8778\n",
      "Epoch 393/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3662 - acc: 0.8488 - val_loss: 0.3327 - val_acc: 0.8756\n",
      "Epoch 394/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3664 - acc: 0.8489 - val_loss: 0.3322 - val_acc: 0.8767\n",
      "Epoch 395/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3648 - acc: 0.8456 - val_loss: 0.3318 - val_acc: 0.8767\n",
      "Epoch 396/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3641 - acc: 0.8449 - val_loss: 0.3313 - val_acc: 0.8767\n",
      "Epoch 397/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3674 - acc: 0.8469 - val_loss: 0.3306 - val_acc: 0.8767\n",
      "Epoch 398/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3674 - acc: 0.8473 - val_loss: 0.3300 - val_acc: 0.8767\n",
      "Epoch 399/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3617 - acc: 0.8472 - val_loss: 0.3297 - val_acc: 0.8767\n",
      "Epoch 400/400\n",
      "8100/8100 [==============================] - 0s - loss: 0.3603 - acc: 0.8481 - val_loss: 0.3291 - val_acc: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff07dd08e50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes_branch = Sequential()\n",
    "genes_branch.add(Dense(128, input_dim=genes.shape[1]))\n",
    "genes_branch.add(Activation('relu'))\n",
    "genes_branch.add(Dropout(0.5))\n",
    "\n",
    "mirs_branch = Sequential()\n",
    "mirs_branch.add(Dense(128, input_dim=genes.shape[1]))\n",
    "mirs_branch.add(Activation('relu'))\n",
    "mirs_branch.add(Dropout(0.5))\n",
    "\n",
    "merged = Merge([genes_branch, mirs_branch], mode='concat') #Multiple Sequential instances can be merged into a \n",
    "# single output via a Merge layer. The output is a layer \n",
    "model = Sequential()\n",
    "model.add(merged)\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "batch_size = 256\n",
    "nb_epoch = 400\n",
    "sgd = SGD(lr=0.0002, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit([genes, mirs], targets,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_split=0.1,\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9728/10999 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3236495136336768, 0.50350031817823182]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "model.evaluate([mirs_t, genes_t], targets_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1)\n",
      "(None, 1, 1)\n",
      "(None, 1)\n",
      "Train on 28800 samples, validate on 3200 samples\n",
      "Epoch 1/200\n",
      "28800/28800 [==============================] - 3s - loss: 2.4717 - acc: 0.7514 - val_loss: 3.9892 - val_acc: 0.7525\n",
      "Epoch 2/200\n",
      "28800/28800 [==============================] - 2s - loss: 3.9971 - acc: 0.7520 - val_loss: 3.9892 - val_acc: 0.7525\n",
      "Epoch 3/200\n",
      "28800/28800 [==============================] - 2s - loss: 3.9971 - acc: 0.7520 - val_loss: 3.9892 - val_acc: 0.7525\n",
      "Epoch 4/200\n",
      "28800/28800 [==============================] - 2s - loss: 3.9971 - acc: 0.7520 - val_loss: 3.9892 - val_acc: 0.7525\n",
      "Epoch 5/200\n",
      "27008/28800 [===========================>..] - ETA: 0s - loss: 3.9818 - acc: 0.7530"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2a99aa2f6d47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m               \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m               validation_split=0.1)\n\u001b[0m",
      "\u001b[1;32m/home/kira/prog/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32m/home/kira/prog/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[0;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kira/prog/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kira/prog/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 1943\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   1944\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kira/prog/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kira/prog/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kira/prog/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/kira/prog/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kira/prog/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dense1 = 128\n",
    "dense2 = 32\n",
    "dense3 = 1\n",
    "\n",
    "# targets \n",
    "genes_branch = Sequential()\n",
    "genes_branch.add(Dense(dense1, input_dim=genes_1.shape[1]))\n",
    "genes_branch.add(Activation('relu'))\n",
    "genes_branch.add(Dropout(0.5))\n",
    "genes_branch.add(Dense(dense2))\n",
    "genes_branch.add(Activation('relu'))\n",
    "genes_branch.add(Dropout(0.5))\n",
    "#genes_branch.add(Dense(dense3))\n",
    "#genes_branch.add(Activation('sigmoid'))\n",
    "\n",
    "# microRNAs\n",
    "mirs_branch = Sequential()\n",
    "mirs_branch.add(Dense(dense1, input_dim=genes_1.shape[1]))\n",
    "mirs_branch.add(Activation('relu'))\n",
    "mirs_branch.add(Dropout(0.5))\n",
    "mirs_branch.add(Dense(dense2))\n",
    "mirs_branch.add(Activation('relu'))\n",
    "mirs_branch.add(Dropout(0.5))\n",
    "#mirs_branch.add(Dense(dense3))\n",
    "#mirs_branch.add(Activation('sigmoid'))\n",
    "\n",
    "R_Q_D = Merge([mirs_branch, genes_branch], mode = 'cos') # See equation (4).\n",
    "model_Rs = Sequential()\n",
    "model_Rs.add(R_Q_D)\n",
    "print model_Rs.output_shape\n",
    "model_Rs.add(Reshape((J + 1, 1)))\n",
    "print model_Rs.output_shape\n",
    "weight = np.array([1]).reshape(1, 1, 1,1)\n",
    "model_Rs.add(Conv1D(1, 1, border_mode = \"same\", input_shape = (J + 1, 1), activation = \"linear\", bias = False,\n",
    "                       weights = [weight]))\n",
    "model_Rs.add(Reshape((J + 1, )))\n",
    "print model_Rs.output_shape\n",
    "\n",
    "sgd = SGD(lr=0.00015, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "#model_Rs.add(Lambda(lambda x: backend.softmax(x), output_shape = (J + 1, )))\n",
    "model_Rs.compile(optimizer = \"rmsprop\", loss = \"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "model_Rs.fit([mirs, genes], targets,\n",
    "             batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5376/10000 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.8224938488006592, 0.47339999999999999]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "model_Rs.evaluate([mirs_t, genes_t], targets_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
